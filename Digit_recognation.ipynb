{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit recognation",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QZ3rfoPQFzyy0EjNmTB_7vgPOTCJkiBc",
      "authorship_tag": "ABX9TyNYV772Q+X8llWFOsQrrnpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelifi/-Mask-Detection-and-Recognition/blob/main/Digit_recognation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoOh14kUiOH6"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiKQ9El0eWhD"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Import the necessary libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "\n",
        "sns.set(style='white', context='notebook', palette='deep')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzhtkDkJiTL-"
      },
      "source": [
        "# Load the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsNSxBc5ecJS"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/digit-recognizer/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/digit-recognizer/test.csv')\n",
        "sub = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/digit-recognizer/sample_submission.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eV3pUsWibrn"
      },
      "source": [
        "# **Set data features and Target labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMpOQH6jfXfU"
      },
      "source": [
        "Y_train = train[\"label\"]\n",
        "X_train = train.drop(labels = [\"label\"], axis = 1) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKq_Z3xbfoiW",
        "outputId": "c7c76074-87ae-4937-99c6-7aca41ad1022"
      },
      "source": [
        "# Load more data sets, if there is no such data, validation accuracy = 0.9964\n",
        "# With this batch of data, the validation accuracy can reach 0.9985\n",
        "(x_train1, y_train1), (x_test1, y_test1) = mnist.load_data()\n",
        "\n",
        "train1 = np.concatenate([x_train1, x_test1], axis=0)\n",
        "y_train1 = np.concatenate([y_train1, y_test1], axis=0)\n",
        "\n",
        "Y_train1 = y_train1\n",
        "X_train1 = train1.reshape(-1, 28*28)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZqUGTtirit"
      },
      "source": [
        "## 2.2 Normalization\n",
        "Moreover the CNN converg faster on [0..1] data than on [0..255]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkpFK_z9frNS"
      },
      "source": [
        "# Normalize data to make CNN faster\n",
        "X_train = X_train / 255.0\n",
        "test = test / 255.0\n",
        "\n",
        "X_train1 = X_train1 / 255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT3bzkumftg0"
      },
      "source": [
        "# Reshape Picture is 3D array (height = 28px, width = 28px , canal = 1)\n",
        "X_train = np.concatenate((X_train.values, X_train1))\n",
        "Y_train = np.concatenate((Y_train, Y_train1))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90MKLhfufuLp"
      },
      "source": [
        "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
        "# canal = 1 => For gray scale\n",
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orIG90OYfwOv"
      },
      "source": [
        "# Convert label to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
        "Y_train = to_categorical(Y_train, num_classes = 10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo8EWBYKfzHQ",
        "outputId": "3417189f-8e2c-478b-b3ed-a5a739e424ba"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oaq75daSi-CK"
      },
      "source": [
        "##  Split training and valdiation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxIuQ-tPf04d"
      },
      "source": [
        "# Split the train and the validation set for the fitting\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poSkGdNIjDKu"
      },
      "source": [
        "# **Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sAjmDlwf30p"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(10, activation = \"softmax\"))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmZsJltf9A6"
      },
      "source": [
        "# Compile model\n",
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV2oXQYRf__O"
      },
      "source": [
        "epochs = 8\n",
        "batch_size = 128"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjPGAWHUgeKM"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False, # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "#datagen.fit(X_train)\n",
        "train_gen = datagen.flow(X_train,Y_train, batch_size=batch_size)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66Mu8vWfjUGp"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XiTF6nsghvK",
        "outputId": "d3daab46-e165-46ea-f3fe-c1d9ed07adb2"
      },
      "source": [
        "history = model.fit( X_train,Y_train,batch_size=128,epochs=10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "788/788 [==============================] - 1607s 2s/step - loss: 0.1003 - accuracy: 0.9687\n",
            "Epoch 2/10\n",
            "788/788 [==============================] - 1607s 2s/step - loss: 0.0358 - accuracy: 0.9888\n",
            "Epoch 3/10\n",
            "788/788 [==============================] - 1609s 2s/step - loss: 0.0269 - accuracy: 0.9915\n",
            "Epoch 4/10\n",
            "788/788 [==============================] - 1594s 2s/step - loss: 0.0218 - accuracy: 0.9930\n",
            "Epoch 5/10\n",
            "788/788 [==============================] - 1599s 2s/step - loss: 0.0192 - accuracy: 0.9940\n",
            "Epoch 6/10\n",
            "788/788 [==============================] - 1595s 2s/step - loss: 0.0165 - accuracy: 0.9949\n",
            "Epoch 7/10\n",
            "788/788 [==============================] - 1602s 2s/step - loss: 0.0164 - accuracy: 0.9949\n",
            "Epoch 8/10\n",
            "788/788 [==============================] - 1612s 2s/step - loss: 0.0129 - accuracy: 0.9959\n",
            "Epoch 9/10\n",
            "788/788 [==============================] - 1610s 2s/step - loss: 0.0117 - accuracy: 0.9961\n",
            "Epoch 10/10\n",
            "788/788 [==============================] - 1634s 2s/step - loss: 0.0116 - accuracy: 0.9960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Mv1LUbgm3P"
      },
      "source": [
        "# Make predictions about test sets\n",
        "results = model.predict(test)\n",
        "\n",
        "# Convert one-hot vector to number\n",
        "results = np.argmax(results,axis = 1)\n",
        "\n",
        "results = pd.Series(results,name=\"Label\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYX-DdTrGB2e"
      },
      "source": [
        "# Save the final result in cnn_mnist_submission.csv\n",
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
        "\n",
        "submission.to_csv(\"cnn_mnist_submission2.csv\",index=False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-_dvBhRiLuZ"
      },
      "source": [
        ""
      ]
    }
  ]
}